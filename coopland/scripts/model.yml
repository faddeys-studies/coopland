training:
#  entropy_strength: 0.0003
  sync_each_n_games: 20
  learning_rate: 0.001
  actor_loss_weight: 0.1
  critic_loss_weight: 1.0
  use_data_augmentation: false
  logit_regularization_strength: 0.01
#  actor_label_smoothing: 0.01

model_type: ac_n
model_hparams:
  rnn_units: [47, 53]

#model_type: ac_v
#model_hparams:
#  max_agents: 2
#  rnn_units: [47, 53]

#model_type: ac_c
#model_hparams:
#  max_agents: 2
#  comm_units: [53]
#  rnn_units: [47]

#model_type: ac_p
#model_hparams:
#  max_agents: 2
#  rnn_units: [47, 53]

maze_size: 5

reward:
  discount_rate: 0.95
  step_reward: 0.5
  exit_reward: 1.0
  exit_reward_diff_decay: 0.8
